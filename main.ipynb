{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13i7KQ9t-CV8"
      },
      "source": [
        "# Problem set 2\n",
        "\n",
        "## Team\n",
        "Please write here your names and team number.\n",
        "\n",
        "* Team name: A\n",
        "* Team members: Giorgio Coppola\n",
        "\n",
        "## Using Colab with GitHub\n",
        "To utilize GPU support for model training, we highly recommend to open this notebook with Google Colab. Simply, change the domain from 'github.com' to 'githubtocolab.com' and refresh the site to open the notebook in Colab.\n",
        "If you haven't used Colab before with private repositories, make sure to grant Colab access to your private repositories (see screenshot) and after that just try to change the domain again.\n",
        "\n",
        "Finally, you should make sure that you add a GPU to your Colab notebook. You can do so by clicking on `Runtime` →  `Change runtime type` → `Hardware accelerator`  →  `GPU`.\n",
        "\n",
        "## Submission\n",
        "\n",
        "Make sure that you always commit and push the changes you make in Colab back to GitHub. To do so from within a Colab notebook, click `File` → `Save a copy in GitHub`. You will be prompted to add a commit message, and after you click OK, the notebook will be pushed to your repository. Only changes that are visible in your GitHub repository on the main branch will be considered for grading. If you close Colab in your browser without pushing your changes to GitHub or saving them on Google Drive, they will be lost.\n",
        "\n",
        "Make sure that all your work has been pushed to GitHub before the deadline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ffVUKx7P6RD"
      },
      "source": [
        "Check that the GPU  enabled in your colab notebook by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPzhNed7P2i9",
        "ExecuteTime": {
          "end_time": "2025-10-14T12:14:48.601410Z",
          "start_time": "2025-10-14T12:14:41.218699Z"
        },
        "outputId": "c62678a5-3fdd-4455-fa7c-b3502768d0b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Check is GPU is enabled\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "\n",
        "# Get specific GPU model\n",
        "if str(device) == \"cuda:0\":\n",
        "  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29zJt4eFI25Y"
      },
      "source": [
        "You will be working with the EuroSAT dataset. The dataset contains 8489 pictures of 3 different land coverage types (crop, herbaceous vegetation and river). Running the lines below will download the data and return a random picture from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MgSuuP3Kjx0",
        "ExecuteTime": {
          "end_time": "2025-10-14T12:15:38.085563Z",
          "start_time": "2025-10-14T12:15:26.981303Z"
        },
        "outputId": "51f208dd-49aa-43c0-b89a-970fdcdfbd9e"
      },
      "outputs": [
        {
          "ename": "URLError",
          "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1344\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1344\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1319\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1318\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1365\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1364\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1314\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1074\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1077\u001b[39m \n\u001b[32m   1078\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1018\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1018\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1460\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1458\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m-> \u001b[39m\u001b[32m1460\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1461\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1046\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1045\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1046\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1317\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1316\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m data = \u001b[43mEuroSAT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#downloads the dataset to your current directory\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe dataset has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m images\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m randint = np.random.randint(\u001b[38;5;28mlen\u001b[39m(data))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Uni/Hertie School/5th Semester/DL/DL-PSs/assignment-2-ps-2-a/.venv/lib/python3.12/site-packages/torchvision/datasets/eurosat.py:42\u001b[39m, in \u001b[36mEuroSAT.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, download, loader)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mself\u001b[39m._data_folder = os.path.join(\u001b[38;5;28mself\u001b[39m._base_folder, \u001b[33m\"\u001b[39m\u001b[33m2750\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_exists():\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Uni/Hertie School/5th Semester/DL/DL-PSs/assignment-2-ps-2-a/.venv/lib/python3.12/site-packages/torchvision/datasets/eurosat.py:67\u001b[39m, in \u001b[36mEuroSAT.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     66\u001b[39m os.makedirs(\u001b[38;5;28mself\u001b[39m._base_folder, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://huggingface.co/datasets/torchgeo/eurosat/resolve/c877bcd43f099cd0196738f714544e355477f3fd/EuroSAT.zip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_base_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mc8fa014336c82ac7804f0398fcb19387\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Uni/Hertie School/5th Semester/DL/DL-PSs/assignment-2-ps-2-a/.venv/lib/python3.12/site-packages/torchvision/datasets/utils.py:388\u001b[39m, in \u001b[36mdownload_and_extract_archive\u001b[39m\u001b[34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[32m    386\u001b[39m     filename = os.path.basename(url)\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m archive = os.path.join(download_root, filename)\n\u001b[32m    391\u001b[39m extract_archive(archive, extract_root, remove_finished)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Uni/Hertie School/5th Semester/DL/DL-PSs/assignment-2-ps-2-a/.venv/lib/python3.12/site-packages/torchvision/datasets/utils.py:118\u001b[39m, in \u001b[36mdownload_url\u001b[39m\u001b[34m(url, root, filename, md5, max_redirect_hops)\u001b[39m\n\u001b[32m    115\u001b[39m     _download_file_from_remote_location(fpath, url)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# expand redirect chain if needed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     url = \u001b[43m_get_redirect_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_hops\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_redirect_hops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# check if file is located on Google Drive\u001b[39;00m\n\u001b[32m    121\u001b[39m     file_id = _get_google_drive_file_id(url)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Uni/Hertie School/5th Semester/DL/DL-PSs/assignment-2-ps-2-a/.venv/lib/python3.12/site-packages/torchvision/datasets/utils.py:63\u001b[39m, in \u001b[36m_get_redirect_url\u001b[39m\u001b[34m(url, max_hops)\u001b[39m\n\u001b[32m     60\u001b[39m headers = {\u001b[33m\"\u001b[39m\u001b[33mMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHEAD\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: USER_AGENT}\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_hops + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     64\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m response.url == url \u001b[38;5;129;01mor\u001b[39;00m response.url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     65\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1392\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1347\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1344\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1345\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1348\u001b[39m     r = h.getresponse()\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\u001b[31mURLError\u001b[39m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import EuroSAT\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "data = EuroSAT(root=os.getcwd(), download=True) #downloads the dataset to your current directory\n",
        "print(f\"The dataset has {len(data)} images\")\n",
        "randint = np.random.randint(len(data))\n",
        "\n",
        "pic, tar = data[randint]\n",
        "print(f\"Picture number {randint} with label: {tar}\")\n",
        "pic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99jkSa_KmrDH"
      },
      "source": [
        "# Task 1: Transform the data (10 pt)\n",
        "\n",
        " Your task is to train a classifier to classify the different land usage types in the dataset. We want to select only the 50 most frequent people in the dataset, all the other people should be mapped to a common class.\n",
        "- Implement the class `rotate` that maps pictures to flipped pictures by 90, 180, 270 or 360°. The class should return an error if you try to rotate the picture by other degrees.\n",
        "- Plot a histogram with the frequencies of each class. Make sure to insert both name and label in the histogram (e.g. `AnnualCrop:0`).\n",
        "- We create a class `RotateEuroSAT` that takes as input the original dataset and returns a new dataset which contains randomly rotated pictures and whose label proportion can be customized.\n",
        "Implement the class method `_create_rotated_dataset` that returns this pictures using the previously implemented `rotate`.\n",
        "- `RotateEuroSAT` should also take care of transforming the pictures to tensors and optionally move the tensor to a GPU device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43onRqgGmalG"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset, Dataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def rotate_picture(picture, rotation):\n",
        "  '''#TODO: implemented most frequent n people'''\n",
        "\n",
        "  return picture\n",
        "\n",
        "\n",
        "def plot_histogram(data):\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(10, 6))\n",
        "  '''#TODO: here your code'''\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "new_pic = rotate_picture(pic, 90) # Example of rotating a picture by 90 degrees\n",
        "same_pic = rotate_picture(pic, 360) # Example of rotating a picture by 360 degrees (should return the same picture)\n",
        "fig, ax = plot_histogram(data)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbpCcsYVrSqr"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "\n",
        "axes[0].imshow(pic)\n",
        "axes[0].set_title(\"Original picture\")\n",
        "axes[1].imshow(new_pic)\n",
        "axes[1].set_title(\"Rotated by 90°\")\n",
        "axes[2].imshow(same_pic)\n",
        "axes[2].set_title(\"Rotated by 360°\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD-Ij7cAt_wu"
      },
      "outputs": [],
      "source": [
        "class RotateEuroSAT(Dataset):\n",
        "    def __init__(self,\n",
        "                 original_data:Dataset,\n",
        "                 length:int,\n",
        "                 shares:list,\n",
        "                 device=None,\n",
        "                 seed=42):\n",
        "\n",
        "        self.original_data = original_data\n",
        "        self.length = length\n",
        "        assert sum(shares)  == 1, \"Shares must sum to 1\"\n",
        "        assert len(shares) == len(original_data.classes), \"Shares must match number of classes\"\n",
        "        self.shares = shares\n",
        "        self.seed = seed\n",
        "        self.device = device\n",
        "        self.dataset = self._create_rotated_dataset()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        picture, label = self.dataset[idx]\n",
        "        return picture, label\n",
        "\n",
        "    def _create_rotated_dataset(self):\n",
        "        \"\"\"#TODO: implement solution\"\"\"\n",
        "        return dataset\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQnnAEHBrSqr"
      },
      "outputs": [],
      "source": [
        "rotated_data = RotateEuroSAT(data,\n",
        "                             length=10**4,\n",
        "                             shares=[1 / len(data.classes) for _ in data.classes],\n",
        "                             seed=42)\n",
        "\n",
        "train_data, test_data = random_split(rotated_data, [0.8, 0.2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuDwG0K5hN8K"
      },
      "source": [
        "## Task 2: Implement a max pooling class and a CNN model(15 pt)\n",
        "Implement a classification model to predict the label of the faces in the dataset. You are free to experiment with the network architecture. However your model **must** contain:\n",
        "- At least one max pooling layer, implemented with `MyMaxPool`,\n",
        "- Convolutional, linear, and pooling layers only,\n",
        "- At least 3 convolutional layers, with at least two different kernel sizes,\n",
        "- A final output layer that is customizable to the number of classes that we want to predict.\n",
        "\n",
        "#### Briefly explain why you chose the particular architecture you implemented (around 2-3 sentences).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVHQhPndvqKu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyMaxPool(nn.Sequential):\n",
        "\n",
        "  def __init__(self,\n",
        "               kernel_size,\n",
        "               stride=1,\n",
        "               padding=0):\n",
        "\n",
        "    super().__init__()\n",
        "    '''#TODO: construction your model'''\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''#TODO: forward step'''\n",
        "\n",
        "\n",
        "class MyCNNModel(nn.Sequential):\n",
        "\n",
        "  def __init__(self,\n",
        "               n_classes):\n",
        "\n",
        "    super().__init__()\n",
        "    '''#TODO: construction your model'''\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''#TODO: forward step'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOVl0a2kHupx"
      },
      "outputs": [],
      "source": [
        "'''#TODO: print one iteration of your model to test its correctness'''\n",
        "\n",
        "my_model = MyCNNModel(n_classes=3)\n",
        "X, y = train_data[0]\n",
        "my_model(X[None, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No6lasumGTkQ"
      },
      "source": [
        "## Training\n",
        "\n",
        "We define a `Trainer` function to train our model that returns avg loss and avg accuracy per epoch. We set the configuration of the trainer is set in the `cfg` dictionary. Use the trainer to train your model and make sure to print and plot avg loss and accuracy using the in-built commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsUHs5doTPD0"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime as dt\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cfg = {\n",
        "    'batch_size': 64,\n",
        "    'criterion': 'CrossEntropyLoss', #change to 'nn.NLLLoss' if you are applying a softmax in the last layer of your model\n",
        "    'epochs': 1,\n",
        "    'learning_rate': 0.001,\n",
        "    'optimizer':'Adam',\n",
        "    'seed':42,\n",
        "\n",
        "}\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, cfg):\n",
        "        self.model = model\n",
        "        self.cfg = cfg\n",
        "\n",
        "        for key, val in cfg.items():\n",
        "            setattr(self, key, val)\n",
        "\n",
        "        self.optimizer = getattr(optim, self.optimizer)(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = getattr(nn, self.criterion)()\n",
        "\n",
        "\n",
        "    def iter_step(self, X, Y):\n",
        "        Y_pred = self.model(X)\n",
        "        loss = self.criterion(Y_pred, Y)\n",
        "        acc = (Y_pred.argmax(dim=-1) == Y).to(torch.float).mean()\n",
        "        return loss, acc\n",
        "\n",
        "    def train(self, dataset):\n",
        "        train_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, generator=torch.manual_seed(self.seed))\n",
        "        avg_loss, avg_acc = [], []\n",
        "        tot_loss, tot_acc = 0, 0\n",
        "        for epoch in range(self.epochs):\n",
        "            iterdata = iter(train_dataloader)\n",
        "            train_size = len(iterdata)\n",
        "            pbar = tqdm(iterable=range(train_size))\n",
        "\n",
        "            for i in pbar:\n",
        "                batch = next(iterdata)\n",
        "                X_batch, Y_batch = batch #this is needed for compatibility with pbar\n",
        "                self.model.train()\n",
        "                self.optimizer.zero_grad()\n",
        "                loss, acc = self.iter_step(X_batch, Y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                tot_loss += loss.item()\n",
        "                tot_acc += acc.item()\n",
        "                avg_loss.append(tot_loss / max(1, len(avg_loss)))\n",
        "                avg_acc.append(tot_acc / max(1, len(avg_acc)))\n",
        "                desc = f'Epoch:{epoch} - Avg loss:{avg_loss[-1]:.5f} - Avg acc:{avg_acc[-1]:.5f}'\n",
        "                pbar.set_description(desc)\n",
        "\n",
        "        return avg_loss, avg_acc\n",
        "\n",
        "    def test(self, dataset):\n",
        "        avg_test_loss, avg_test_acc = [], []\n",
        "        test_loss, test_acc = 0, 0\n",
        "        self.model.eval()\n",
        "        test_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, generator=torch.manual_seed(self.seed))\n",
        "\n",
        "        for X_batch, Y_batch in iter(test_dataloader):\n",
        "            loss, acc = self.iter_step(X_batch, Y_batch)\n",
        "            test_loss += loss.item()\n",
        "            test_acc += acc\n",
        "            avg_test_loss.append(test_loss / max(1, len(avg_test_loss)))\n",
        "            avg_test_acc.append(test_acc / max(1, len(avg_test_acc)))\n",
        "\n",
        "        return avg_test_loss, avg_test_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iDGmuiGksqP"
      },
      "outputs": [],
      "source": [
        "'''#TODO: train your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "my_trainer = Trainer(my_model, cfg)\n",
        "train_loss, train_acc = my_trainer.train(train_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(train_loss)), train_loss)\n",
        "ax1.plot(range(len(train_acc)), train_acc)\n",
        "ax0.set_title('Training loss')\n",
        "ax1.set_title('Training accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDfgU18pllpT"
      },
      "outputs": [],
      "source": [
        "'''#TODO: test your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "test_loss, test_acc = my_trainer.test(test_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(test_loss)), test_loss)\n",
        "ax1.plot(range(len(test_acc)), test_acc)\n",
        "ax0.set_title('Test loss')\n",
        "ax1.set_title('Test accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AvPUd76zVOk"
      },
      "source": [
        "## Task 3: Tune your training hyperparameters (optional, 10 pt)\n",
        "\n",
        "Implement a method <code>grid_search</code>, which looks for the best possible learning rates and training batch sizes for your model <code>MyCNNModel</code> and returns the best possible model, the corresponding training configuration, and the final training avg losses and accuracies (as numbers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJtGS3EB4NFy"
      },
      "outputs": [],
      "source": [
        "def grid_search(train_dataset, cfg, learning_rates=[10**-1, 10**-2, 10**-3], batch_sizes=[2**5, 2**6, 2**7]):\n",
        "    '''#TODO: here your code '''\n",
        "    return best_model, best_cfg, best_avg_loss, best_avg_acc\n",
        "\n",
        "\n",
        "best_model, best_cfg, best_avg_loss, best_avg_acc = grid_search(train_data, cfg, learning_rates=[10**-1, 10**-2, 10**-3], batch_sizes=[2**5, 2**6, 2**7])\n",
        "print(f\"Best model achieves {best_avg_loss:.2f} loss and {best_avg_acc:.1%} accuracy\").\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLLCQpv14Gsx"
      },
      "source": [
        "## Task 3: Load and fine-tune a pre-trained model (10 pt)\n",
        "\n",
        "<ul>\n",
        "  <li>Load and train a pre-trained model for classification problems, such as those made available in <a href=\"https://huggingface.co/docs/timm\">Hugging Face's timm library</a>. </li>\n",
        "  <li> Make sure to modify the output layer to be compatible with the number of classes. </li>\n",
        "  <li>Print a summary of your results.</li>\n",
        "  <li>Briefly explain why you chose the particular architecture you did (around 2-3 sentences).</li>\n",
        "  </ul>\n",
        "  \n",
        "<b>Note</b>: in case you run into computing-related (e.g. memory) issues, consider choosing another model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na1giLKlT0M3"
      },
      "outputs": [],
      "source": [
        "'''#TODO: import and fine-tune a pretrained model'''\n",
        "loaded_model = None #here your loaded model\n",
        "loaded_trainer = Trainer(loaded_model, cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXjFg5gNl1iO"
      },
      "outputs": [],
      "source": [
        "'''#TODO: train your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "train_loss, train_acc = loaded_trainer.train(train_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(train_loss)), train_loss)\n",
        "ax1.plot(range(len(train_acc)), train_acc)\n",
        "ax0.set_title('Training loss')\n",
        "ax1.set_title('Training accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjKQ8pVql1iO"
      },
      "outputs": [],
      "source": [
        "'''#TODO: test your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "test_loss, test_acc = loaded_trainer.test(test_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(test_loss)), test_loss)\n",
        "ax1.plot(range(len(test_acc)), test_acc)\n",
        "ax0.set_title('Test loss')\n",
        "ax1.set_title('Test accuracy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhkmytKNU_Z2"
      },
      "source": [
        "<a name=\"results-and-discussion\"></a>\n",
        "# Task  4: Results and discussion (5pt)\n",
        "\n",
        "Report the final metrics and make a few comments on the overall performance for the networks you implemented (3-4 lines).\n",
        "\n",
        "| Test metric         | your model | pre-trained model | your tuned model (optional) |\n",
        "|---------------------|--------------------|-------------------|-----------------------|\n",
        "| Accuracy (train)           |              |             |                |                     \n",
        "| Loss (train)               |               |             |                |    \n",
        "| Accuracy (test)           |              |             |                |                     \n",
        "| Loss (test)               |               |             |                |              \n",
        "             \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}